{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para criação dessa automatização é necessário que exista uma \"lista_tratados.txt\", no mesmo endereço que deste, que catalogue os meses em que já foram processados.\\\n",
    "Este pipeline então requisita a lista de datasets existentes no database e então compara com o catálogo, se existir datasets que não estão catalogados o processo de tratamento é executado, senão nada acontece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grequests\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import warnings\n",
    "import urllib.parse\n",
    "import datetime\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo Variáveis para usar o API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Url para chamar a API e escolha dos métodos\n",
    "\n",
    "base_endpoint = 'https://opendata.nhsbsa.net/api/3/action/'\n",
    "package_list_method = 'package_list'     # Lista dos datasets no portal\n",
    "package_show_method = 'package_show?id=' # Lista todos recursos de dataset\n",
    "action_method = 'datastore_search_sql?'  # método para ação SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o volume de dados é muito grande, assumiu-se que as consultas e resultados desejados nesta automação para os consecutivos meses são as mesmas que foram feitas anteriormente, e não todos os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtendo lista de Datasets.\n",
    "datasets_response = requests.get(base_endpoint + \"package_show?id=english-prescribing-data-epd\").json()\n",
    "\n",
    "#listando todos os metadados dos datasets.\n",
    "lista_df  = pd.json_normalize(datasets_response['result']['resources'])\n",
    "\n",
    "#selecionando apenas os nomes dos datasets.\n",
    "listameses = lista_df['name']\n",
    "\n",
    "#Transformando lista em formato panda series para python list.\n",
    "listameses = listameses.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando a lista de dados já tratados.\n",
    "arquivo = open('lista_tratados.txt', 'r')\n",
    "\n",
    "#criando lista com todos datasets já tratados.\n",
    "listatratados = [i for i in arquivo.readlines()]\n",
    "\n",
    "#retirando \\n\n",
    "listatratados = [i.replace('\\n', '') for i in listatratados]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista que terá os dados não tratados, começa como uma cópia da lista de datasets no site.\n",
    "listantratados = listameses.copy()\n",
    "\n",
    "#removendo a lista de dados tratados da lista dos datasets no site.\n",
    "for i in listatratados:\n",
    "    if i in listantratados:\n",
    "        listantratados.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if listantratados != []:\n",
    "    for j in listantratados:\n",
    "        \n",
    "        #Dataset para o mês\n",
    "        nome_dataset = j\n",
    "\n",
    "        #criando variáveis com as datas\n",
    "        mes = nome_dataset[len(nome_dataset)-2:len(nome_dataset)]\n",
    "        ano = nome_dataset[len(nome_dataset)-6:len(nome_dataset)-2]\n",
    "\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #Regiões químicos mais vendidos por região\n",
    "        #-----------------------------------------------------------------------------\n",
    "\n",
    "        #Criando o query para obter todas regiões no dataset\n",
    "        query_todas_regioes = \"SELECT \" \\\n",
    "                            \"DISTINCT regional_office_name \" \\\n",
    "                            f\"FROM `{nome_dataset}` \"\n",
    "\n",
    "        #Método para codificar o método em uma url\n",
    "\n",
    "        todas_regioes_api_call = f\"{base_endpoint}\" \\\n",
    "                                f\"{action_method}\" \\\n",
    "                                \"resource_id=\" \\\n",
    "                                f\"{nome_dataset}\" \\\n",
    "                                \"&\" \\\n",
    "                                \"sql=\" \\\n",
    "                                f\"{urllib.parse.quote(query_todas_regioes)}\"\n",
    "\n",
    "        #Resposta JSON\n",
    "        json_regioes = requests.get(todas_regioes_api_call).json()\n",
    "\n",
    "        #Extrai os dados requisitados para um dataframe\n",
    "        todas_regioes_df  = pd.json_normalize(json_regioes['result']['result']['records'])\n",
    "\n",
    "        regioes_df = pd.DataFrame()\n",
    "\n",
    "        #for loop para extrair cada dataset regional e então concatená-los\n",
    "        for i in range(0, len(todas_regioes_df)) :\n",
    "        \n",
    "            #Query para uma região\n",
    "            query_uma_regiao = \"SELECT \" \\\n",
    "                                    \"regional_office_name, \" \\\n",
    "                                    \"chemical_substance_bnf_descr, \" \\\n",
    "                                    \"sum(total_quantity) as quantity \" \\\n",
    "                                    \"FROM \" \\\n",
    "                                    f\"`{nome_dataset}` \" \\\n",
    "                                    \"WHERE \" \\\n",
    "                                    \"regional_office_name = \" f\"'{todas_regioes_df.regional_office_name[i]}' \" \\\n",
    "                                    \"GROUP BY \" \\\n",
    "                                    \"regional_office_name, \" \\\n",
    "                                    \"chemical_substance_bnf_descr \" \\\n",
    "                                    \"ORDER BY \" \\\n",
    "                                    \"quantity DESC \" \\\n",
    "                                    \"LIMIT 15\"\n",
    "\n",
    "            #criação da url de requisição ao API\n",
    "            uma_regiao_api_call = f\"{base_endpoint}\" \\\n",
    "                                    f\"{action_method}\" \\\n",
    "                                    \"resource_id=\" \\\n",
    "                                    f\"{nome_dataset}\" \\\n",
    "                                    \"&\" \\\n",
    "                                    \"sql=\" \\\n",
    "                                    f\"{urllib.parse.quote(query_uma_regiao)}\"\n",
    "\n",
    "            #Resultado em JSON temporário\n",
    "            json_uma_regiao = requests.get(uma_regiao_api_call).json()\n",
    "\n",
    "            #Extração apenas dos resultados do JSON e transformação em um dataframe\n",
    "            uma_regiao_df  = pd.json_normalize(json_uma_regiao['result']['result']['records'])\n",
    "\n",
    "            #Concatenação dos dataframes de região\n",
    "            frames = [regioes_df, uma_regiao_df]\n",
    "            regioes_df = pd.concat(frames, sort = False)\n",
    "\n",
    "        #Arrumando o índice\n",
    "        regioes_df = regioes_df.reset_index(drop = True)\n",
    "\n",
    "        #Exportando para um CSV\n",
    "        regioes_df.to_csv(f'automatizados/regiaotop10_{ano}{mes}.csv')\n",
    "\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #10 Químicos mais custosos por mês\n",
    "        #-----------------------------------------------------------------------------\n",
    "\n",
    "        #Criação do dataset em que será concatenado\n",
    "        custosos_df = pd.DataFrame()\n",
    "\n",
    "        #Query para um mês\n",
    "        query_um_mes = \"SELECT \" \\\n",
    "                                \"chemical_substance_bnf_descr, \" \\\n",
    "                                \"sum(actual_cost) as cost \" \\\n",
    "                                \"FROM \" \\\n",
    "                                f\"`{nome_dataset}` \" \\\n",
    "                                \"GROUP BY \" \\\n",
    "                                \"chemical_substance_bnf_descr \" \\\n",
    "                                \"ORDER BY \" \\\n",
    "                                \"cost DESC \" \\\n",
    "                                \"LIMIT 10\"\n",
    "\n",
    "        #criação da url de requisição ao API\n",
    "        um_mes_api_call = f\"{base_endpoint}\" \\\n",
    "                                f\"{action_method}\" \\\n",
    "                                \"resource_id=\" \\\n",
    "                                f\"{nome_dataset}\" \\\n",
    "                                \"&\" \\\n",
    "                                \"sql=\" \\\n",
    "                                f\"{urllib.parse.quote(query_um_mes)}\"\n",
    "\n",
    "        #Resultado em JSON temporário\n",
    "        json_um_mes = requests.get(um_mes_api_call).json()\n",
    "\n",
    "        #Extração apenas dos resultados do JSON e transformação em um dataframe\n",
    "        um_mes_df  = pd.json_normalize(json_um_mes['result']['result']['records'])\n",
    "\n",
    "        #Concatenação dos dataframes mensais\n",
    "        frames = [custosos_df, um_mes_df]\n",
    "        custosos_df = pd.concat(frames, sort = False)\n",
    "\n",
    "        #Agrupando e ordenando os 10 químicos mais custosos em todos os meses\n",
    "        custosos_df = custosos_df.groupby('chemical_substance_bnf_descr').sum().sort_values('cost', ascending=False).head(10)\n",
    "\n",
    "        #Arrumando o índice\n",
    "        custosos_df = custosos_df.reset_index(drop = False)\n",
    "\n",
    "        #Visualização\n",
    "        custosos_df\n",
    "        \n",
    "        #exportação para CSV dos químicos mais custosos em todos os meses\n",
    "        custosos_df.to_csv(f'automatizados/custotop10_{ano}{mes}.csv')   \n",
    "\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #Químicos mais prescritos por mês\n",
    "        #-----------------------------------------------------------------------------\n",
    "\n",
    "        #Criação do dataset em que será concatenado\n",
    "        prescritos_df = pd.DataFrame()\n",
    "\n",
    "        #Query para um mês\n",
    "        query_um_mes = \"SELECT \" \\\n",
    "                                \"bnf_description, \" \\\n",
    "                                \"items \" \\\n",
    "                                \"FROM \" \\\n",
    "                                f\"`{nome_dataset}` \" \\\n",
    "                                \"LIMIT 10\"\n",
    "\n",
    "        #criação da url de requisição ao API\n",
    "        um_mes_api_call = f\"{base_endpoint}\" \\\n",
    "                                f\"{action_method}\" \\\n",
    "                                \"resource_id=\" \\\n",
    "                                f\"{nome_dataset}\" \\\n",
    "                                \"&\" \\\n",
    "                                \"sql=\" \\\n",
    "                                f\"{urllib.parse.quote(query_um_mes)}\"\n",
    "\n",
    "        #Resultado em JSON temporário\n",
    "        json_um_mes = requests.get(um_mes_api_call).json()\n",
    "\n",
    "        #Extração apenas dos resultados do JSON e transformação em um dataframe\n",
    "        um_mes_df  = pd.json_normalize(json_um_mes['result']['result']['records'])\n",
    "\n",
    "        #Concatenação dos dataframes mensais\n",
    "        frames = [prescritos_df, um_mes_df]\n",
    "        prescritos_df = pd.concat(frames, sort = False)\n",
    "\n",
    "        #Agrupando e ordenando os 10 medicamentos mais prescritos em todos os meses\n",
    "        prescritos_df = prescritos_df.groupby('bnf_description').sum().sort_values('items', ascending=False).head(10)\n",
    "\n",
    "        #Arrumando o índice\n",
    "        prescritos_df = prescritos_df.reset_index(drop = False)\n",
    "\n",
    "        #exportando o CSV\n",
    "        prescritos_df.to_csv(f'automatizados/prescritos_{ano}{mes}.csv')\n",
    "\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #Mais prescritos por prescriber\n",
    "        #-----------------------------------------------------------------------------\n",
    "\n",
    "        #lista com todas as prescribers\n",
    "        prescribers_df = pd.DataFrame()\n",
    "\n",
    "        #Query para um mês\n",
    "        query_um_mes = \"SELECT \" \\\n",
    "                    \"T.practice_name, \" \\\n",
    "                    \"T.chemical_substance_bnf_descr, \" \\\n",
    "                    \"T.items \" \\\n",
    "                    \"FROM \" \\\n",
    "                    f\"`{nome_dataset}` as T \" \\\n",
    "                    \"WHERE \" \\\n",
    "                    f\"T.items = ( SELECT MAX(items) FROM `{nome_dataset}` WHERE practice_name = T.practice_name)\" \n",
    "\n",
    "        #criação da url de requisição ao API\n",
    "        um_mes_api_call = f\"{base_endpoint}\" \\\n",
    "                            f\"{action_method}\" \\\n",
    "                            \"resource_id=\" \\\n",
    "                            f\"{nome_dataset}\" \\\n",
    "                            \"&\" \\\n",
    "                            \"sql=\" \\\n",
    "                            f\"{urllib.parse.quote(query_um_mes)}\"\n",
    "\n",
    "        #Resultado em JSON temporário\n",
    "        json_um_mes = requests.get(um_mes_api_call).json()\n",
    "\n",
    "        #Extração apenas dos resultados do JSON e transformação em um dataframe\n",
    "        um_mes_df  = pd.json_normalize(json_um_mes['result']['result']['records'])\n",
    "\n",
    "        #dataframes de prescribers\n",
    "        frames = [prescribers_df, um_mes_df]\n",
    "        prescribers_df = pd.concat(frames, sort= False)\n",
    "\n",
    "        #limpeza e tratamento dos dados concatenados\n",
    "        prescribers_df = prescribers_df.groupby(['practice_name','chemical_substance_bnf_descr'])['items'].sum().reset_index().sort_values(\n",
    "            ['practice_name', 'items'], ascending=False).drop_duplicates(\n",
    "            ['practice_name']).sort_values('practice_name')\n",
    "\n",
    "        #arrumando o índice\n",
    "        prescribers_df = prescribers_df.reset_index(drop = True)\n",
    "\n",
    "        #Exportando para CSV\n",
    "        prescribers_df.to_csv(f'automatizados/prescribers_{ano}{mes}.csv')\n",
    "\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #Prescribers adicionadas\n",
    "        #-----------------------------------------------------------------------------\n",
    "\n",
    "        #criando a variável que armazenará o mês anterior ao dataset\n",
    "        if int(mes) == 1:\n",
    "            mes0 = 12\n",
    "            ano = int(nome_dataset[len(nome_dataset)-6:len(nome_dataset)-3])-1\n",
    "            nome_dataset0 = f'EPD_{ano}{mes0}'\n",
    "        else:\n",
    "            mes0 = int(mes) - 1\n",
    "            if mes0 < 10:\n",
    "                mes0 = f\"0{mes0}\"\n",
    "            nome_dataset0 = f'EPD_{ano}{mes0}'\n",
    "\n",
    "        #Query para o mês 6 para quantidade de prescribers\n",
    "        query_mes0 = \"SELECT \" \\\n",
    "                        \"count(distinct(practice_name))\" \\\n",
    "                        \"FROM \" \\\n",
    "                        f\"`{nome_dataset0}`\" \\\n",
    "\n",
    "        #criação da url de requisição ao API\n",
    "        mes0_api_call = f\"{base_endpoint}\" \\\n",
    "                                f\"{action_method}\" \\\n",
    "                                \"resource_id=\" \\\n",
    "                                f\"{nome_dataset0}\" \\\n",
    "                                \"&\" \\\n",
    "                                \"sql=\" \\\n",
    "                                f\"{urllib.parse.quote(query_mes0)}\"\n",
    "\n",
    "        #Resultado em JSON\n",
    "        json_mes0 = requests.get(mes0_api_call).json()\n",
    "\n",
    "        #Extração apenas dos resultados do JSON e transformação em um dataframe\n",
    "        mes0_df  = pd.json_normalize(json_mes0['result']['result']['records'])\n",
    "\n",
    "        #Query para o mês 7 para quantidade de prescribers\n",
    "        query_mes1 = \"SELECT \" \\\n",
    "                        \"count(distinct(practice_name))\" \\\n",
    "                        \"FROM \" \\\n",
    "                        f\"`{nome_dataset}`\" \\\n",
    "\n",
    "        #criação da url de requisição ao API\n",
    "        mes1_api_call = f\"{base_endpoint}\" \\\n",
    "                                f\"{action_method}\" \\\n",
    "                                \"resource_id=\" \\\n",
    "                                f\"{nome_dataset}\" \\\n",
    "                                \"&\" \\\n",
    "                                \"sql=\" \\\n",
    "                                f\"{urllib.parse.quote(query_mes1)}\"\n",
    "\n",
    "        #Resultado em JSON\n",
    "        json_mes1 = requests.get(mes1_api_call).json()\n",
    "\n",
    "        #Extração apenas dos resultados do JSON e transformação em um dataframe\n",
    "        mes1_df  = pd.json_normalize(json_mes1['result']['result']['records'])\n",
    "\n",
    "        #Diferença é o acréscimo de prescritores.\n",
    "        diff = mes1_df.f0_[0] - mes0_df.f0_[0]\n",
    "\n",
    "        #Exportando a diferença para um txt\n",
    "        with open(f'automatizados/aumentoPrescriber_{ano}{mes}.txt', 'w') as f:\n",
    "            if diff > 0:\n",
    "                f.write(f'Houve um acréscimo de {diff} prescribers no mês {mes} em relação ao {mes0}, no ano de {ano}')\n",
    "            elif diff < 0:\n",
    "                diff = diff * -1\n",
    "                f.write(f'Houve uma diminuição de {diff} prescribers no mês {mes} em relação ao {mes0}, no ano de {ano}')\n",
    "            else:\n",
    "                f.write(f'Não houve alteração no número de prescribers entre {mes0} e {mes}')\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #Prescribers em mais de uma região\n",
    "        #-----------------------------------------------------------------------------\n",
    "\n",
    "        #Criação do dataset em que será concatenado\n",
    "        presregiao_df = pd.DataFrame()\n",
    "\n",
    "        #Query para um mês\n",
    "        query_um_mes = \"SELECT \" \\\n",
    "                                \"practice_name, \" \\\n",
    "                                \"COUNT(DISTINCT(regional_office_name)) as regqt \" \\\n",
    "                                \"FROM \" \\\n",
    "                                f\"`{nome_dataset}` \" \\\n",
    "                                \"GROUP BY \" \\\n",
    "                                    \"practice_name\"\n",
    "\n",
    "        #criação da url de requisição ao API\n",
    "        um_mes_api_call = f\"{base_endpoint}\" \\\n",
    "                                f\"{action_method}\" \\\n",
    "                                \"resource_id=\" \\\n",
    "                                f\"{nome_dataset}\" \\\n",
    "                                \"&\" \\\n",
    "                                \"sql=\" \\\n",
    "                                f\"{urllib.parse.quote(query_um_mes)}\"\n",
    "\n",
    "        #Resultado em JSON temporário\n",
    "        json_um_mes = requests.get(um_mes_api_call).json()\n",
    "\n",
    "        #Extração apenas dos resultados do JSON e transformação em um dataframe\n",
    "        um_mes_df  = pd.json_normalize(json_um_mes['result']['result']['records'])\n",
    "\n",
    "        #Concatenação dos dataframes mensais\n",
    "        frames = [presregiao_df, um_mes_df]\n",
    "        presregiao_df = pd.concat(frames, sort = False)\n",
    "\n",
    "        #arrumando o dataframe para facilitar a leitura\n",
    "        presregiao_df = presregiao_df[['practice_name', 'regqt']]\n",
    "\n",
    "        #excluindo linhas em que as regiões são iguais a 1\n",
    "        presregiao_df = presregiao_df[presregiao_df.regqt > 1]\n",
    "\n",
    "        #Ordenando os valores\n",
    "        presregiao_df = presregiao_df.sort_values('regqt', ascending=False)\n",
    "\n",
    "        #Arrumando o índice\n",
    "        presregiao_df = presregiao_df.reset_index(drop = True)\n",
    "        \n",
    "        #Exportando para CSV\n",
    "        presregiao_df.to_csv(f'automatizados/precriberPorRegiao_{ano}{mes}.csv')\n",
    "\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #Preço médio dos prescritos\n",
    "        #-----------------------------------------------------------------------------\n",
    "\n",
    "        #Criação do dataset em que será concatenado\n",
    "        medio_df = pd.DataFrame()\n",
    "\n",
    "        #Query para um mês\n",
    "        query_um_mes = \"SELECT \" \\\n",
    "                                \"distinct(bnf_description), \" \\\n",
    "                                \"sum(total_quantity) as qt , \" \\\n",
    "                                \"sum(actual_cost) as cost \" \\\n",
    "                            \"FROM \" \\\n",
    "                                f\"`{nome_dataset}` \" \\\n",
    "                            \"GROUP BY \" \\\n",
    "                                \"bnf_description\"\n",
    "\n",
    "        #criação da url de requisição ao API\n",
    "        um_mes_api_call = f\"{base_endpoint}\" \\\n",
    "                                f\"{action_method}\" \\\n",
    "                                \"resource_id=\" \\\n",
    "                                f\"{nome_dataset}\" \\\n",
    "                                \"&\" \\\n",
    "                                \"sql=\" \\\n",
    "                                f\"{urllib.parse.quote(query_um_mes)}\"\n",
    "\n",
    "        #Resultado em JSON temporário\n",
    "        json_um_mes = requests.get(um_mes_api_call).json()\n",
    "\n",
    "        #Extração apenas dos resultados do JSON e transformação em um dataframe\n",
    "        medio_df  = pd.json_normalize(json_um_mes['result']['result']['records'])\n",
    "\n",
    "        #Criando a coluna de média\n",
    "        medio_df['mean'] = medio_df.cost/medio_df.qt \n",
    "\n",
    "        #excluindo colunas de custo e quantidade\n",
    "        medio_df.drop(['cost','qt'], axis = 1, inplace= True)\n",
    "\n",
    "        #Arrumando o índice\n",
    "        medio_df = medio_df.reset_index(drop = True)\n",
    "\n",
    "        #exportando CSV\n",
    "        medio_df.to_csv(f'automatizados/medio_{ano}{mes}.csv')\n",
    "\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #Preço prescrição de maior valor\n",
    "        #-----------------------------------------------------------------------------\n",
    "\n",
    "        #dataframe que receberá os dados\n",
    "        maiorvalor_df = pd.DataFrame()\n",
    "\n",
    "        #Query para um mês\n",
    "        query_um_mes = \"SELECT \" \\\n",
    "                        \"T.practice_name, \" \\\n",
    "                        \"T.bnf_description, \" \\\n",
    "                        \"T.actual_cost \" \\\n",
    "                        \"FROM \" \\\n",
    "                        f\"`{nome_dataset}` as T \" \\\n",
    "                        \"WHERE \" \\\n",
    "                        f\"T.actual_cost = ( SELECT MAX(actual_cost) FROM `{nome_dataset}` WHERE practice_name = T.practice_name)\" \n",
    "\n",
    "        #criação da url de requisição ao API\n",
    "        um_mes_api_call = f\"{base_endpoint}\" \\\n",
    "                                f\"{action_method}\" \\\n",
    "                                \"resource_id=\" \\\n",
    "                                f\"{nome_dataset}\" \\\n",
    "                                \"&\" \\\n",
    "                                \"sql=\" \\\n",
    "                                f\"{urllib.parse.quote(query_um_mes)}\"\n",
    "\n",
    "        #Resultado em JSON temporário\n",
    "        json_um_mes = requests.get(um_mes_api_call).json()\n",
    "\n",
    "        #Extração apenas dos resultados do JSON e transformação em um dataframe\n",
    "        um_mes_df  = pd.json_normalize(json_um_mes['result']['result']['records'])\n",
    "\n",
    "        #dataframes de prescribers\n",
    "        frames = [maiorvalor_df, um_mes_df]\n",
    "        maiorvalor_df = pd.concat(frames, sort= False)\n",
    "\n",
    "        #Arrumando o índice\n",
    "        maiorvalor_df = maiorvalor_df.reset_index(drop = True)\n",
    "\n",
    "        #Exportando para CSV\n",
    "        maiorvalor_df.to_csv(f'automatizados/maiorValorPorPrescriber_{ano}{mes}.csv')\n",
    "\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #-----------------------------------------------------------------------------\n",
    "        #Escrevendo na lista de verificação o mês tratado\n",
    "\n",
    "        #abrindo o arquivo de lista\n",
    "        with open('lista_tratados.txt', 'a') as arquivo:\n",
    "            arquivo.write(f'{j}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b168dbd905a704e810f5bba0e95eadf2474778d38b3d7edbf61b6d0b620bdea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
